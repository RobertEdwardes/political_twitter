{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": [
                "import datetime\r\n",
                "import sqlite3 as sql \r\n",
                "import requests\r\n",
                "import re\r\n",
                "import nltk\r\n",
                "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
                "import pandas as pd\r\n",
                "import numpy as np\r\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
                "import json \r\n",
                "import networkx\r\n",
                "from config_new import config\r\n",
                "import time\r\n",
                "\r\n",
                "nltk.download('punkt')\r\n",
                "nltk.download('stopwords')\r\n",
                "nltk.download('averaged_perceptron_tagger')\r\n",
                "nltk.download('vader_lexicon')\r\n",
                "nltk.download('wordnet')\r\n",
                "nltk.download('omw-1.4')\r\n",
                "if config['file_path']:\r\n",
                "    os.chdir(config['file_path'])"
            ],
            "metadata": {
                "azdata_cell_guid": "814e6310-8b0f-45ca-8382-4f2616df9f15",
                "language": "python",
                "tags": []
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\vaugh\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\vaugh\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\vaugh\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     C:\\Users\\vaugh\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\vaugh\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to\n[nltk_data]     C:\\Users\\vaugh\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n"
                }
            ],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": [
                "bearertoken=config['bear_token']\r\n",
                "headers = {'Authorization': 'Bearer ' +\r\n",
                "       bearertoken, 'Content-Type': 'application/json'}\r\n",
                "con = sql.connect(config['database'])\r\n",
                "\r\n",
                "def init_users(con, headers):\r\n",
                "    base_handels = {'NRSC':'NRSC',\r\n",
                "        'DSCC':'DSCC',\r\n",
                "        'DCCC':'DCCC',\r\n",
                "        'NRCC':'NRCC',\r\n",
                "        'RNC' :'GOP',\r\n",
                "        'DNC':'DNC'}\r\n",
                "    base_handels = ','.join(base_handels.values())\r\n",
                "    BASE_URL_QUERY = f'https://api.twitter.com/2/users/by?usernames={base_handels}&user.fields=created_at&expansions=pinned_tweet_id&tweet.fields=author_id,created_at'\r\n",
                "    auth_response_QUERY = requests.get(BASE_URL_QUERY,  headers=headers)\r\n",
                "    auth_response_RESPONSE = json.loads(auth_response_QUERY.text)\r\n",
                "    cur = con.cursor()\r\n",
                "    cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS twitter_users (user_id INTEGER, user_name TEXT, parent_id INTEGER)\r\n",
                "    \"\"\")\r\n",
                "    con.commit()\r\n",
                "    for i in auth_response_RESPONSE['data']:\r\n",
                "        cur.execute(f\"\"\"INSERT INTO twitter_users (user_id, user_name, parent_id) VALUES ({i['id']},'{i['username']}',0)\"\"\")\r\n",
                "        con.commit()\r\n",
                "\r\n",
                "def get_follows(base_id, con, headers, next_token=None):\r\n",
                "    cur = con.cursor()\r\n",
                "    retry = True \r\n",
                "    while retry:   \r\n",
                "        try:\r\n",
                "            if next_token:\r\n",
                "                BASE_URL_QUERY = f'https://api.twitter.com/2/users/11134252/following?user.fields=created_at&expansions=pinned_tweet_id&tweet.fields=created_at&max_results=1000&pagination_token={next_token}'\r\n",
                "            else:\r\n",
                "                BASE_URL_QUERY = f'https://api.twitter.com/2/users/{base_id}/following?user.fields=created_at&expansions=pinned_tweet_id&tweet.fields=created_at&max_results=1000'\r\n",
                "            auth_response_QUERY = requests.get(BASE_URL_QUERY,  headers=headers)\r\n",
                "            auth_response_RESPONSE = json.loads(auth_response_QUERY.text)\r\n",
                "            if auth_response_RESPONSE['data']:\r\n",
                "                for i in auth_response_RESPONSE['data']:\r\n",
                "                    cur.execute(f\"\"\"INSERT INTO twitter_users (user_id, user_name, parent_id) VALUES ({i['id']},'{i['username']}', {base_id})\"\"\")\r\n",
                "                    con.commit()\r\n",
                "            if auth_response_QUERY.status_code == 429:\r\n",
                "                time.sleep(900)\r\n",
                "                get_follows(base_id, con, headers, next_token)\r\n",
                "            elif 'next_token' in auth_response_RESPONSE['meta'].keys():\r\n",
                "                get_follows(base_id, con, headers, auth_response_RESPONSE['meta']['next_token'])\r\n",
                "            else:\r\n",
                "                retry = False\r\n",
                "        except:\r\n",
                "            time.sleep(900)\r\n",
                "\r\n",
                "# init_users(con, headers)\r\n",
                "# df = pd.read_sql_query(\"\"\"SELECT user_id from twitter_users\"\"\", con)\r\n",
                "# user_ids = df['user_id'].tolist()\r\n",
                "# for user_id in user_ids:\r\n",
                "#     get_follows(user_id, con, headers)\r\n",
                "    \r\n",
                "# con.close()"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "24bbe98e-e70e-427e-bea2-06569edef1c2",
                "tags": [
                    "hide_input"
                ]
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": [
                "sql_latlonpop_query = '''SELECT STNAME, COUNAME, MAX(POPULATION) AS POPULATION, LATITUDE, LONGITUDE\r\n",
                "                            FROM Count_Pop_Centroid\r\n",
                "                            GROUP BY\r\n",
                "                                STNAME'''\r\n",
                "\r\n",
                "template_twitter_search = f'filter:verified near:{lat},{lon} within:10km'\r\n",
                "headers = {'Authorization': 'Bearer ' +\r\n",
                "    config['bear_token'], 'Content-Type': 'application/json'}\r\n",
                "BASE_URL_QUERY = f'https://api.twitter.com/2/tweets/search/recent?query={template_twitter_search}&expansions=author_id&start_time={start_time}'\r\n",
                "auth_response_QUERY = requests.get(BASE_URL_QUERY,  headers=headers)\r\n",
                "res = auth_response_QUERY.json()"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "a5c68d99-c065-4512-aeea-66756b561dea"
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}